# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/43_visualization.ipynb.

# %% auto 0
__all__ = ['LRFinderCB', 'HooksCallback', 'append_stats', 'get_hist', 'get_min', 'ActivationStatsCB']

# %% ../nbs/43_visualization.ipynb 4
from .utils import *
from .dataloaders import *
from .models import *
from .initialization import *
from .trainer import *
from .training import *
from .recording import *

import fastcore.all as fc
from torch.optim.lr_scheduler import ExponentialLR
import math
import torch.nn as nn
import torch
import matplotlib.pyplot as plt,matplotlib as mpl
from datasets import load_dataset, Dataset
import torchvision.transforms.functional as TF,torch.nn.functional as F

from torcheval.metrics import MulticlassAccuracy
from IPython.display import clear_output
import dill as pickle

# %% ../nbs/43_visualization.ipynb 9
class LRFinderCB(Callback):
    order = 1
    def __init__(self,lr_mult=1.3): fc.store_attr()
    
    def before_fit(self,trainer):
        pickle.dump(trainer,open('_tmp.pkl','wb'),protocol=pickle.HIGHEST_PROTOCOL)
        self.scheduler = ExponentialLR(optimizer=trainer.opt,gamma=self.lr_mult)
        self.lrs, self.losses = fc.L(), fc.L()
        self.min = math.inf
        
    def before_batch(self,trainer):
        if not trainer.training: raise CancelEpochException()
        
    def after_batch(self,trainer):
        loss = to_cpu(trainer.loss)
        if loss > self.min * 3: raise CancelEpochException()
        self.lrs.append(trainer.opt.param_groups[0]['lr'])
        self.losses.append(loss)        
        if loss < self.min: self.min = loss
        self.scheduler.step()
        
    def after_fit(self,_):
        plt.figure(figsize=(12,4))
        plt.plot(self.lrs,self.losses)
        plt.xscale('log')
        plt.title('Learning Rate Finder'); plt.xlabel('Learning Rate'); plt.ylabel('Losses') 
        plt.show()
        
    def cleanup_fit(self,trainer):
        _name = retrieve_global_name(trainer)
        globals()[_name[0]] = pickle.load(open('_tmp.pkl','rb'))

# %% ../nbs/43_visualization.ipynb 13
class HooksCallback(Callback):
    def __init__(self, hookfunc, module_filter=fc.noop, on_train=True, on_valid=False, modules=None):
        fc.store_attr()
    
    def before_fit(self, trainer):
        if self.modules: modules=self.modules
        else: modules = fc.filter_ex(trainer.model.modules(), self.module_filter)
        self.hooks = Hooks(modules, fc.bind(self._hookfunc, trainer))

    def _hookfunc(self, trainer, *args, **kwargs):
        if (self.on_train and trainer.training) or (self.on_valid and not trainer.training): self.hookfunc(*args, **kwargs)

    def after_fit(self, trainer): self.hooks.remove()
    def __iter__(self): return iter(self.hooks)
    def __len__(self): return len(self.hooks)

# %% ../nbs/43_visualization.ipynb 14
def append_stats(hook, module, inp, outp):
    if not hasattr(hook,'stats'): hook.stats = ([],[],[])
    acts = to_cpu(outp)
    hook.stats[0].append(acts.mean())
    hook.stats[1].append(acts.std())
    hook.stats[2].append(acts.abs().histc(40,0,10))

# Thanks to @ste for initial version of histgram plotting code
def get_hist(h):
    return torch.stack(h.stats[2]).t().float().log1p()

# %% ../nbs/43_visualization.ipynb 15
def get_min(h):
    h1 = torch.stack(h.stats[2]).t().float()
    return h1[0]/h1.sum(0)

class ActivationStatsCB(HooksCallback):
    def __init__(self, module_filter=fc.noop): super().__init__(append_stats, module_filter)

    def color_dim(self, figsize=(11,6)):
        fig,axes = get_grid(len(self), figsize=figsize)
        for ax,h in zip(axes.flat, self):
            show_image(get_hist(h), ax, origin='lower')

    def dead_chart(self, figsize=(11,5)):
        fig,axes = get_grid(len(self), figsize=figsize)
        for ax,h in zip(axes.flatten(), self):
            ax.plot(get_min(h))
            ax.set_ylim(0,1)

    def plot_stats(self, figsize=(10,4)):
        fig,axs = plt.subplots(1,2, figsize=figsize)
        for h in self:
            for i in 0,1: axs[i].plot(h.stats[i])
        axs[0].set_title('Means')
        axs[1].set_title('Stdevs')
        plt.legend(fc.L.range(self))
