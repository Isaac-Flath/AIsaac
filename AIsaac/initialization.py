# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/21_initialization.ipynb.

# %% auto 0
__all__ = ['lsuv_init']

# %% ../nbs/21_initialization.ipynb 4
from isaacai.utils import *
from isaacai.dataloaders import *
from isaacai.models import *

from datetime import datetime, timedelta
import torchvision.transforms.functional as TF,torch.nn.functional as F
import math, time

import matplotlib.pyplot as plt
import matplotlib as mpl
import fastcore.all as fc
import torch
from torch import nn, Tensor
from datasets import load_dataset, Dataset
from torch.utils.data import DataLoader
import pandas as pd , numpy as np
from torcheval.metrics import MulticlassAccuracy,Mean
from torch.optim.lr_scheduler import ExponentialLR

import dill as pickle
from fastprogress.fastprogress import master_bar, progress_bar
import inspect
import torchinfo


# %% ../nbs/21_initialization.ipynb 11
def _lsuv_stats(hook, mod, inp, outp):
    acts = to_cpu(outp)
    hook.mean = acts.mean()
    hook.std = acts.std()

def lsuv_init(model, trainable_module, xb, measurement_module=None,targ_mean=0.5,target_std=1,max_loops=100):
    if hasattr(trainable_module,'bias') or hasattr(trainable_module,'weight'): 
        if measurement_module is None: measurement_module = trainable_module
        hook = Hook(measurement_module, _lsuv_stats)
        while model(xb) is not None and (abs(hook.std-targ_mean)>1e-3) or (abs(hook.mean-targ_mean)>1e-3):
            with torch.no_grad():
                if (abs(hook.std-targ_mean)<1e-3) or (abs(hook.mean-targ_mean)<1e-3): break
                if hasattr(trainable_module,'bias'): trainable_module.bias -= hook.mean - targ_mean
                if hasattr(trainable_module,'weight'): trainable_module.weight.data /= hook.std / target_std
            max_loops-=1
            if max_loops < 1: break
            
        hook.remove()
