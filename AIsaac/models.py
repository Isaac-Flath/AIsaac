# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_models.ipynb.

# %% auto 0
__all__ = ['conv', 'get_model_conv', 'fully_connected', 'get_model_fc']

# %% ../nbs/20_models.ipynb 4
from isaacai.utils import *
from isaacai.dataloaders import *

import matplotlib.pyplot as plt,matplotlib as mpl
import torchvision.transforms.functional as TF,torch.nn.functional as F
import fastcore.all as fc
import torch
from torch import nn, Tensor
from datasets import load_dataset, Dataset
from torch.utils.data import DataLoader
import pandas as pd, numpy as np

# %% ../nbs/20_models.ipynb 8
def conv(ni, nf, kernel_size=3, stride=2, act=nn.ReLU, norm=None, bias=None):
    if bias is None: bias = not isinstance(norm, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d))
    layers = [nn.Conv2d(ni, nf, stride=stride, kernel_size=kernel_size, padding=kernel_size//2, bias=bias)]
    if norm: layers.append(norm(nf))
    if act: layers.append(act())
    return nn.Sequential(*layers)

def get_model_conv(act=nn.ReLU, nfs=None, norm=None):
    if nfs is None: nfs = [1,8,16,32,64]
    layers = [conv(nfs[i], nfs[i+1], act=act, norm=norm) for i in range(len(nfs)-1)]
    return nn.Sequential(*layers, conv(nfs[-1],10, act=None, norm=False, bias=True),
                         nn.Flatten()).to(def_device)

# %% ../nbs/20_models.ipynb 9
def fully_connected(n_inp,n_hidden1,n_hidden2,n_out,act):
       return [nn.Flatten(),
               nn.Linear(n_inp, n_hidden1),act(),
               nn.Linear(n_hidden1, n_hidden2),act(),
               nn.Linear(n_hidden2, n_out)]
    
def get_model_fc(act=nn.ReLU,n_inp=28*28,n_hidden1=128,n_hidden2=64,n_out=10):
    return nn.Sequential(*fully_connected(28*28,128,64,10,act)).to(def_device)
