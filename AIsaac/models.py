# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_models.ipynb.

# %% auto 0
__all__ = ['get_model_timm', 'conv', 'get_model_conv']

# %% ../nbs/20_models.ipynb 5
from .utils import *
from .dataloaders import *

import matplotlib.pyplot as plt,matplotlib as mpl
import torchvision.transforms.functional as TF,torch.nn.functional as F
import fastcore.all as fc
import torch
from torch import nn, Tensor
from datasets import load_dataset, Dataset
from torch.utils.data import DataLoader
import pandas as pd, numpy as np
import timm


# %% ../nbs/20_models.ipynb 12
@fc.delegates(timm.create_model)
def get_model_timm(model_name,**kwargs): 
    '''Loads model from timm, see timm.list_models for options'''
    return timm.create_model(model_name,**kwargs)

# %% ../nbs/20_models.ipynb 14
def conv(ni, nf, kernel_size=3, stride=2, act=nn.ReLU, norm=None, bias=None):
    if bias is None: bias = not isinstance(norm, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d))
    layers = [nn.Conv2d(ni, nf, stride=stride, kernel_size=kernel_size, padding=kernel_size//2, bias=bias)]
    if norm: layers.append(norm(nf))
    if act: layers.append(act())
    return nn.Sequential(*layers)

def get_model_conv(act=nn.ReLU, nfs=None, norm=None):
    if nfs is None: nfs = [1,8,16,32,64]
    layers = [conv(nfs[i], nfs[i+1], act=act, norm=norm) for i in range(len(nfs)-1)]
    return nn.Sequential(*layers, conv(nfs[-1],10, act=None, norm=False, bias=True),
                         nn.Flatten()).to(def_device)
