{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ffbf61-9481-4824-8522-7200a88f7db1",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc79a30-d809-4631-b0bb-aee0f7c7c0cd",
   "metadata": {},
   "source": [
    "The `isaacai` library is an extremely flexible framework that uses callbacks **a lot**.  They are probably more widely used than in any other framework.  Because of this it's very important to understand how to use `isaacai` uses them and how you can leverage that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8b0af-d88f-4258-9ae2-a12482056cbc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here I will set up the needed pieces for the tutorial.  This includes imports and loading a small subset of the fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cda67-fa0d-4a01-a9d0-c43a4e1263bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75d55b-d644-4383-ab1e-872607c47394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isaacai.all import *\n",
    "import matplotlib.pyplot as plt,matplotlib as mpl\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a860278-7a7d-477e-b755-ae7aad038b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b470376-1fb5-40da-aeff-94aa4dda9853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024214982986450195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6c5113f43e48f4a3c165b855d926b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)\n",
    "_dataset = sample_dataset_dict(_dataset)\n",
    "dls = DataLoaders.from_dataset_dict(_dataset, 64, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400045d-2fb0-44b8-8794-110686c820df",
   "metadata": {},
   "source": [
    "## Very basic Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730075e5-a3d0-46bb-8e2e-dbc96d47f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.5580000281333923, 'train_loss': 1.8707503662109375, 'valid_loss': 1.4094869384765625, 'epoch': 0, 'elapsed': datetime.timedelta(microseconds=237908)}\n",
      "{'Accuracy': 0.6539999842643738, 'train_loss': 1.0959883117675782, 'valid_loss': 1.026219970703125, 'epoch': 1, 'elapsed': datetime.timedelta(microseconds=186135)}\n",
      "{'Accuracy': 0.6819999814033508, 'train_loss': 0.793328239440918, 'valid_loss': 0.8982598266601562, 'epoch': 2, 'elapsed': datetime.timedelta(microseconds=181564)}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  SimpleNet(28*28,64,10), \n",
    "                  callbacks=[BasicTrainCB(),MetricsCB(Accuracy=MulticlassAccuracy()), DeviceCB()])\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf2d5d-2531-4955-af61-d61b355bf4a0",
   "metadata": {},
   "source": [
    "So we passed in a `DataLoaders`, a pytorch loss, a pytorch optimizer, a pytorch model, and some callbacks.  As you can see by running `Trainer.fit` it ran a full training loop.  **The training loop is defined entirely in the callbacks**.  For this tutorial we are focusing on the callbacks.  Please refer to pytorch documentation for the pytorch pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45e8ee-ab8f-456c-8da5-28b74ceefa35",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c07a46-1eaa-4a56-9a1c-a805724c4c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
