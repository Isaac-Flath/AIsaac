{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/python3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from AIsaac.utils import *\n",
    "from AIsaac.dataloaders import *\n",
    "from AIsaac.models import *\n",
    "from AIsaac.initialization import *\n",
    "from AIsaac.trainer import *\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "import math, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd , numpy as np\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import dill as pickle\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import inspect\n",
    "import torchinfo\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "# mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 391.99it/s]\n"
     ]
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = sample_dataset_dict(_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dataset_dict(_dataset, 1024, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OneBatchCB(Callback):\n",
    "    order = 100\n",
    "    def after_batch(self, learn): raise CancelFitException      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasicTrainCB(Callback):\n",
    "    '''Callback for basic pytorch training loop'''\n",
    "    def predict(self,trainer): trainer.preds = trainer.model(trainer.batch[0])\n",
    "    def get_loss(self,trainer): trainer.loss = trainer.loss_func(trainer.preds,trainer.batch[1])\n",
    "    def backward(self,trainer): trainer.loss.backward()\n",
    "    def step(self,trainer): trainer.opt.step()\n",
    "    def zero_grad(self,trainer): trainer.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeviceCB(Callback):\n",
    "    '''Callback to train on specific device'''\n",
    "    def __init__(self, device=def_device): self.device=device\n",
    "    def before_fit(self, trainer):\n",
    "        '''Moves model to device'''\n",
    "        if hasattr(trainer.model, 'to'): trainer.model.to(self.device)\n",
    "    def before_batch(self, trainer): \n",
    "        '''moves batch to device'''\n",
    "        trainer.batch = to_device(trainer.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MomentumTrainCB(BasicTrainCB):\n",
    "    def __init__(self,momentum): self.momentum = momentum\n",
    "    def zero_grad(self,trainer): \n",
    "        '''Multiply grads by momentum (instead of zero)'''\n",
    "        with torch.no_grad():\n",
    "            for p in trainer.model.parameters(): p.grad *= self.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  get_model_conv(), \n",
    "                  callbacks=[BasicTrainCB(), DeviceCB(),OneBatchCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/aisaac/AIsaac/trainer.py:95\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, n_epochs, lr, callbacks, train, valid)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(train,valid)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [o\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m callbacks]]\n",
      "File \u001b[0;32m~/github/aisaac/AIsaac/trainer.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(train,valid)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [o\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m callbacks]]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.summarize_callbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseSchedulerCB(Callback):\n",
    "    def __init__(self, scheduler_func): fc.store_attr()\n",
    "    def before_fit(self, trainer): \n",
    "        '''Initializes scheduled with opt'''\n",
    "        self.scheduler = self.scheduler_func(trainer.opt)\n",
    "    def _step(self, trainer):\n",
    "        if trainer.training: self.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export        \n",
    "class BatchSchedulerCB(BaseSchedulerCB):\n",
    "    '''Steps scheduler'''\n",
    "    def after_batch(self, trainer): self._step(trainer) \n",
    "    \n",
    "class EpochSchedulerCB(BaseSchedulerCB):\n",
    "    '''Steps scheduler'''\n",
    "    def after_epoch(self, trainer): self._step(trainer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OneCycleSchedulerCB(BatchSchedulerCB):\n",
    "    @fc.delegates(to=torch.optim.lr_scheduler.OneCycleLR,\n",
    "                  but=['optimizer','max_lr','total_steps','steps_per_epoch','epochs'])\n",
    "    def __init__(self,**kwargs):\n",
    "        self.scheduler_kwargs = kwargs\n",
    "        self.scheduler_func =  torch.optim.lr_scheduler.OneCycleLR\n",
    "    \n",
    "    def before_fit(self,trainer):\n",
    "        '''Initializes Scheduler'''\n",
    "        total_steps = trainer.n_epochs*len(trainer.dls.train)\n",
    "        self.scheduler = self.scheduler_func(trainer.opt, max_lr=trainer.lr, total_steps=total_steps,**self.scheduler_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccelerateCB(BasicTrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    def __init__(self, n_inp=1, mixed_precision=\"fp16\"):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.acc = Accelerator(mixed_precision=mixed_precision)\n",
    "        \n",
    "    def before_fit(self, learn):\n",
    "        '''Wraps model, opt, data in accelerate'''\n",
    "        learn.model,learn.opt,learn.dls.train,learn.dls.valid = self.acc.prepare(\n",
    "            learn.model, learn.opt, learn.dls.train, learn.dls.valid)\n",
    "\n",
    "        \n",
    "    def backward(self, learn): \n",
    "        '''Using accelerate for backward pass'''\n",
    "        self.acc.backward(learn.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
