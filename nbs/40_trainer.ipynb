{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/python3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from AIsaac.utils import *\n",
    "from AIsaac.dataloaders import *\n",
    "from AIsaac.models import *\n",
    "from AIsaac.initialization import *\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "import math, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd , numpy as np\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import dill as pickle\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import inspect\n",
    "import torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "# mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 354.29it/s]\n"
     ]
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = sample_dataset_dict(_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dataset_dict(_dataset, 1024, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback: order=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cb_steps = ['before_fit','before_epoch', 'before_batch','predict','get_loss','before_backward','backward', 'step',\n",
    "            'zero_grad','after_batch','cleanup_batch','after_epoch','cleanup_epoch','after_fit','cleanup_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def summarize_callbacks(trainer):    \n",
    "    res = pd.DataFrame(columns=['Step','Callback','Doc String'])\n",
    "    callbacks = [getattr(trainer,o) for o in trainer.callbacks]\n",
    "    for attr in cb_steps: \n",
    "        for callback in sorted(callbacks, key=lambda x: getattr(x, 'order')):\n",
    "            callback_name = callback.__class__.__name__\n",
    "            callback = getattr(trainer,callback_name)\n",
    "            if getattr(callback,attr,None) is not None:\n",
    "                docstring = getattr(callback,attr).__doc__\n",
    "                row = pd.DataFrame([[attr,callback_name,fc.ifnone(docstring,'')],],columns=res.columns,index=[''])\n",
    "                res = pd.concat([res,row])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_model(model,batch,row_settings=(\"var_names\",),verbose=0,depth=3,col_names=(\"input_size\",\"output_size\",\"kernel_size\")):\n",
    "    \n",
    "    # Other useful columns: \"num_params\",\"mult_adds\"\n",
    "    return torchinfo.summary(model,input_data=batch,row_settings=row_settings,verbose=verbose,depth=depth,col_names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class Trainer:\n",
    "    def __init__(self, dls, loss_func, opt_func, model, callbacks):\n",
    "        self.add_callbacks(callbacks)\n",
    "        fc.store_attr(but='callbacks')\n",
    "            \n",
    "    @with_cbs('batch', CancelBatchException)\n",
    "    def one_batch(self):\n",
    "        self.run_callbacks(['predict','get_loss'])\n",
    "        if self.training: self.run_callbacks(['before_backward','backward','step','zero_grad'])\n",
    "    \n",
    "    @with_cbs('epoch',CancelEpochException)\n",
    "    def _one_epoch(self):\n",
    "        for self.batch_num,self.batch in zip(self.batches,self.dl): self.one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self.batches = range(len(self.dl))\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit', CancelFitException)\n",
    "    def _fit(self,train, valid):\n",
    "        for self.epoch in self.epochs: \n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "    \n",
    "    def fit(self, n_epochs=3, lr=1e-3, callbacks=None,train=True,valid=True):\n",
    "        fc.store_attr('n_epochs,lr')\n",
    "        try:\n",
    "            self.add_callbacks(fc.L(callbacks))\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "            self.epochs = range(self.n_epochs)\n",
    "            self._fit(train,valid)\n",
    "        finally:\n",
    "            self.callbacks = [o for o in self.callbacks if o not in [o.__class__.__name__ for o in callbacks]]\n",
    "                                                        \n",
    "    @property\n",
    "    def training(self): return self.model.training\n",
    "    \n",
    "    def add_callbacks(self,callbacks,force=False): add_callbacks(self,callbacks,force)\n",
    "\n",
    "    def run_callbacks(self,method_names):\n",
    "        cbs = [getattr(self,o) for o in self.callbacks]\n",
    "        for method_name in fc.L(method_names): run_callbacks(cbs,method_name,self)\n",
    "            \n",
    "    def summarize_model(self): return summarize_model(model=self.model,batch=fc.first(self.dls.train)[0])\n",
    "    def summarize_callbacks(self): return summarize_callbacks(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  get_model_conv(),\n",
    "                  callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Kernel Shape\n",
       "===================================================================================================================\n",
       "Sequential (Sequential)                  [500, 1, 28, 28]          [500, 10]                 --\n",
       "├─Sequential (0)                         [500, 1, 28, 28]          [500, 8, 14, 14]          --\n",
       "│    └─Conv2d (0)                        [500, 1, 28, 28]          [500, 8, 14, 14]          [3, 3]\n",
       "│    └─ReLU (1)                          [500, 8, 14, 14]          [500, 8, 14, 14]          --\n",
       "├─Sequential (1)                         [500, 8, 14, 14]          [500, 16, 7, 7]           --\n",
       "│    └─Conv2d (0)                        [500, 8, 14, 14]          [500, 16, 7, 7]           [3, 3]\n",
       "│    └─ReLU (1)                          [500, 16, 7, 7]           [500, 16, 7, 7]           --\n",
       "├─Sequential (2)                         [500, 16, 7, 7]           [500, 32, 4, 4]           --\n",
       "│    └─Conv2d (0)                        [500, 16, 7, 7]           [500, 32, 4, 4]           [3, 3]\n",
       "│    └─ReLU (1)                          [500, 32, 4, 4]           [500, 32, 4, 4]           --\n",
       "├─Sequential (3)                         [500, 32, 4, 4]           [500, 64, 2, 2]           --\n",
       "│    └─Conv2d (0)                        [500, 32, 4, 4]           [500, 64, 2, 2]           [3, 3]\n",
       "│    └─ReLU (1)                          [500, 64, 2, 2]           [500, 64, 2, 2]           --\n",
       "├─Sequential (4)                         [500, 64, 2, 2]           [500, 10, 1, 1]           --\n",
       "│    └─Conv2d (0)                        [500, 64, 2, 2]           [500, 10, 1, 1]           [3, 3]\n",
       "├─Flatten (5)                            [500, 10, 1, 1]           [500, 10]                 --\n",
       "===================================================================================================================\n",
       "Total params: 30,154\n",
       "Trainable params: 30,154\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 113.45\n",
       "===================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 12.52\n",
       "Params size (MB): 0.12\n",
       "Estimated Total Size (MB): 14.21\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.summarize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
