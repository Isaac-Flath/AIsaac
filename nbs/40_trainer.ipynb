{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from isaacai.utils import *\n",
    "from isaacai.dataloaders import *\n",
    "from isaacai.models import *\n",
    "from isaacai.initialization import *\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "import math, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd , numpy as np\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import dill as pickle\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import inspect\n",
    "import torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "# mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031388044357299805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6811c3bd18e43a49398bfbfb3accbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = sample_dataset_dict(_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dataset_dict(_dataset, 1024, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback: order=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cb_steps = ['before_fit','before_epoch', 'before_batch','predict','get_loss','before_backward','backward', 'step',\n",
    "            'zero_grad','after_batch','cleanup_batch','after_epoch','cleanup_epoch','after_fit','cleanup_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def summarize_callbacks(trainer):    \n",
    "    res = pd.DataFrame(columns=['Step','Callback','Doc String'])\n",
    "    callbacks = [getattr(trainer,o) for o in trainer.callbacks]\n",
    "    for attr in cb_steps: \n",
    "        for callback in sorted(callbacks, key=lambda x: getattr(x, 'order')):\n",
    "            callback_name = callback.__class__.__name__\n",
    "            callback = getattr(trainer,callback_name)\n",
    "            if getattr(callback,attr,None) is not None:\n",
    "                docstring = getattr(callback,attr).__doc__\n",
    "                row = pd.DataFrame([[attr,callback_name,fc.ifnone(docstring,'')],],columns=res.columns,index=[''])\n",
    "                res = pd.concat([res,row])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_model(model,batch,row_settings=(\"var_names\",),verbose=0,depth=3,col_names=(\"input_size\",\"output_size\",\"kernel_size\",\"num_params\",\"mult_adds\")): \n",
    "    return torchinfo.summary(model,input_data=batch,row_settings=row_settings,verbose=verbose,depth=depth,col_names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class Trainer:\n",
    "    def subclassing_method(self,**kwargs): pass\n",
    "\n",
    "    def __init__(self, dls, loss_func, opt_func, model, callbacks, **kwargs):\n",
    "        self.add_callbacks(callbacks)\n",
    "        fc.store_attr(but='callbacks')\n",
    "        self.subclassing_method(**kwargs)\n",
    "            \n",
    "    @with_cbs('batch', CancelBatchException)\n",
    "    def one_batch(self):\n",
    "        self.run_callbacks(['predict','get_loss'])\n",
    "        if self.training: self.run_callbacks(['before_backward','backward','step','zero_grad'])\n",
    "    \n",
    "    @with_cbs('epoch',CancelEpochException)\n",
    "    def _one_epoch(self):\n",
    "        for self.batch_num,self.batch in zip(self.batches,self.dl): self.one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self.batches = range(len(self.dl))\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit', CancelFitException)\n",
    "    def _fit(self,train, valid):\n",
    "        for self.epoch in self.epochs: \n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "    \n",
    "    def fit(self, n_epochs=3, lr=1e-3, callbacks=None,train=True,valid=True):\n",
    "        fc.store_attr('n_epochs,lr')\n",
    "        try:\n",
    "            self.add_callbacks(fc.L(callbacks))\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "            self.epochs = range(self.n_epochs)\n",
    "            self._fit(train,valid)\n",
    "        finally:\n",
    "            self.callbacks = [o for o in self.callbacks if o not in fc.L(callbacks)]\n",
    "                                                        \n",
    "    @property\n",
    "    def training(self): return self.model.training\n",
    "    \n",
    "    def add_callbacks(self,callbacks,force=False): add_callbacks(self,callbacks,force)\n",
    "\n",
    "    def run_callbacks(self,method_names):\n",
    "        cbs = [getattr(self,o) for o in self.callbacks]\n",
    "        for method_name in fc.L(method_names): run_callbacks(cbs,method_name,self)\n",
    "            \n",
    "    def summarize_model(self): return summarize_model(model=self.model,batch=fc.first(self.dls.train)[0])\n",
    "    def summarize_callbacks(self): return summarize_callbacks(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  get_model_conv(),\n",
    "                  callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Kernel Shape              Param #                   Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "Sequential (Sequential)                  [500, 1, 28, 28]          [500, 10]                 --                        --                        --\n",
       "├─Sequential (0)                         [500, 1, 28, 28]          [500, 8, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d (0)                        [500, 1, 28, 28]          [500, 8, 14, 14]          [3, 3]                    80                        7,840,000\n",
       "│    └─ReLU (1)                          [500, 8, 14, 14]          [500, 8, 14, 14]          --                        --                        --\n",
       "├─Sequential (1)                         [500, 8, 14, 14]          [500, 16, 7, 7]           --                        --                        --\n",
       "│    └─Conv2d (0)                        [500, 8, 14, 14]          [500, 16, 7, 7]           [3, 3]                    1,168                     28,616,000\n",
       "│    └─ReLU (1)                          [500, 16, 7, 7]           [500, 16, 7, 7]           --                        --                        --\n",
       "├─Sequential (2)                         [500, 16, 7, 7]           [500, 32, 4, 4]           --                        --                        --\n",
       "│    └─Conv2d (0)                        [500, 16, 7, 7]           [500, 32, 4, 4]           [3, 3]                    4,640                     37,120,000\n",
       "│    └─ReLU (1)                          [500, 32, 4, 4]           [500, 32, 4, 4]           --                        --                        --\n",
       "├─Sequential (3)                         [500, 32, 4, 4]           [500, 64, 2, 2]           --                        --                        --\n",
       "│    └─Conv2d (0)                        [500, 32, 4, 4]           [500, 64, 2, 2]           [3, 3]                    18,496                    36,992,000\n",
       "│    └─ReLU (1)                          [500, 64, 2, 2]           [500, 64, 2, 2]           --                        --                        --\n",
       "├─Sequential (4)                         [500, 64, 2, 2]           [500, 10, 1, 1]           --                        --                        --\n",
       "│    └─Conv2d (0)                        [500, 64, 2, 2]           [500, 10, 1, 1]           [3, 3]                    5,770                     2,885,000\n",
       "├─Flatten (5)                            [500, 10, 1, 1]           [500, 10]                 --                        --                        --\n",
       "=====================================================================================================================================================================\n",
       "Total params: 30,154\n",
       "Trainable params: 30,154\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 113.45\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 12.52\n",
       "Params size (MB): 0.12\n",
       "Estimated Total Size (MB): 14.21\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.summarize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
