{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from isaacai.utils import *\n",
    "from isaacai.dataloaders import *\n",
    "from isaacai.models import *\n",
    "from isaacai.initialization import *\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "import math, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd , numpy as np\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import dill as pickle\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import inspect\n",
    "import torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "# mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03156137466430664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721f5f67a9e644dd864d52a97c550345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = sample_dataset_dict(_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dataset_dict(_dataset, 1024, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cb_steps = ['before_fit','before_epoch', 'before_batch','predict','get_loss','before_backward','backward', 'step',\n",
    "            'zero_grad','after_batch','cleanup_batch','after_epoch','cleanup_epoch','after_fit','cleanup_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def summarize_callbacks(trainer):    \n",
    "    res = pd.DataFrame(columns=['Step','Callback','Doc String'])\n",
    "    callbacks = [getattr(trainer,o) for o in trainer.callbacks]\n",
    "    for attr in cb_steps: \n",
    "        for callback in sorted(callbacks, key=lambda x: getattr(x, 'order',0)):\n",
    "            callback_name = callback.__class__.__name__\n",
    "            callback = getattr(trainer,callback_name)\n",
    "            if getattr(callback,attr,None) is not None:\n",
    "                docstring = getattr(callback,attr).__doc__\n",
    "                row = pd.DataFrame([[attr,callback_name,fc.ifnone(docstring,'')],],columns=res.columns,index=[''])\n",
    "                res = pd.concat([res,row])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class Trainer:\n",
    "    def subclassing_method(self,**kwargs): pass\n",
    "\n",
    "    def __init__(self, dls, loss_func, opt_func, model, callbacks, **kwargs):\n",
    "        self.add_callbacks(callbacks)\n",
    "        fc.store_attr(but='callbacks')\n",
    "        self.subclassing_method(**kwargs)\n",
    "            \n",
    "    @with_cbs('batch', CancelBatchException)\n",
    "    def one_batch(self):\n",
    "        self.run_callbacks(['predict','get_loss'])\n",
    "        if self.training: self.run_callbacks(['before_backward','backward','step','zero_grad'])\n",
    "    \n",
    "    @with_cbs('epoch',CancelEpochException)\n",
    "    def _one_epoch(self):\n",
    "        for self.batch_num,self.batch in zip(self.batches,self.dl): self.one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self.batches = range(len(self.dl))\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit', CancelFitException)\n",
    "    def _fit(self,train, valid):\n",
    "        for self.epoch in self.epochs: \n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "    \n",
    "    def fit(self, n_epochs=3, lr=1e-3, callbacks=None,train=True,valid=True):\n",
    "        fc.store_attr('n_epochs,lr')\n",
    "        try:\n",
    "            self.add_callbacks(fc.L(callbacks))\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "            self.epochs = range(self.n_epochs)\n",
    "            self._fit(train,valid)\n",
    "        finally:\n",
    "            self.callbacks = [o for o in self.callbacks if o not in fc.L(callbacks)]\n",
    "                                                        \n",
    "    @property\n",
    "    def training(self): return self.model.training\n",
    "    \n",
    "    def add_callbacks(self,callbacks,force=False): add_callbacks(self,callbacks,force)\n",
    "\n",
    "    def run_callbacks(self,method_names):\n",
    "        cbs = [getattr(self,o) for o in self.callbacks]\n",
    "        for method_name in fc.L(method_names): run_callbacks(cbs,method_name,self)\n",
    "            \n",
    "    def summarize_model(self): return torchinfo.summary(self.model,input_data=fc.first(self.dls.train)[0])\n",
    "    def summarize_callbacks(self): return summarize_callbacks(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  get_model_conv(),\n",
    "                  callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [500, 10]                 --\n",
       "├─Sequential: 1-1                        [500, 8, 14, 14]          --\n",
       "│    └─Conv2d: 2-1                       [500, 8, 14, 14]          80\n",
       "│    └─ReLU: 2-2                         [500, 8, 14, 14]          --\n",
       "├─Sequential: 1-2                        [500, 16, 7, 7]           --\n",
       "│    └─Conv2d: 2-3                       [500, 16, 7, 7]           1,168\n",
       "│    └─ReLU: 2-4                         [500, 16, 7, 7]           --\n",
       "├─Sequential: 1-3                        [500, 32, 4, 4]           --\n",
       "│    └─Conv2d: 2-5                       [500, 32, 4, 4]           4,640\n",
       "│    └─ReLU: 2-6                         [500, 32, 4, 4]           --\n",
       "├─Sequential: 1-4                        [500, 64, 2, 2]           --\n",
       "│    └─Conv2d: 2-7                       [500, 64, 2, 2]           18,496\n",
       "│    └─ReLU: 2-8                         [500, 64, 2, 2]           --\n",
       "├─Sequential: 1-5                        [500, 10, 1, 1]           --\n",
       "│    └─Conv2d: 2-9                       [500, 10, 1, 1]           5,770\n",
       "├─Flatten: 1-6                           [500, 10]                 --\n",
       "==========================================================================================\n",
       "Total params: 30,154\n",
       "Trainable params: 30,154\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 113.45\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 12.52\n",
       "Params size (MB): 0.12\n",
       "Estimated Total Size (MB): 14.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.summarize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
