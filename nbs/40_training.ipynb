{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from isaacai.utils import *\n",
    "from isaacai.dataloaders import *\n",
    "from isaacai.models import *\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from fastcore.all import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030692100524902344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1471b9ecd02448d3ba55455bad55cc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13, 4, 79)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(*load_fashion_mnist(sample=2000,batch_size=128))\n",
    "dls.x_name,dls.y_name = 'image','label'\n",
    "len(dls.train), len(dls.valid),len(dls.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_callbacks(callbacks, method_name, trainer=None):\n",
    "    for callback in sorted(callbacks, key=lambda x: getattr(x, 'order',0)):\n",
    "        callback_method = getattr(callback, method_name,None)\n",
    "        if callback_method is not None: callback_method(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ProgressCB:\n",
    "    def __init__(self, precision=4, **metrics):\n",
    "        store_attr(names=['precision'])\n",
    "        self.metrics = metrics\n",
    "        self.loss_train, self.loss_valid = Mean(), Mean()\n",
    "        self.stats_epoch = L()\n",
    "        \n",
    "    def log(self,x): print(x)\n",
    "    \n",
    "    def before_batch(self,trainer):\n",
    "        self.batch_size = len(trainer.batch[trainer.dls.y_name])\n",
    "    def after_batch(self,trainer):\n",
    "        # Collect loss, metrics and store\n",
    "        if trainer.training: self.loss_train.update(to_cpu(trainer.loss.detach()),weight=self.batch_size)\n",
    "        else: \n",
    "            self.loss_valid.update(to_cpu(trainer.loss.detach()),weight=self.batch_size)\n",
    "            for name, metric in self.metrics.items():\n",
    "                self.metrics[name].update(to_cpu(trainer.preds.detach()),to_cpu(trainer.batch[trainer.dls.y_name]))\n",
    "            \n",
    "    def before_epoch(self,trainer): self.st = datetime.now()\n",
    "    def after_epoch(self,trainer):\n",
    "\n",
    "        # compute metrics and append to epoch stats and display\n",
    "        _stats = {'epoch':trainer.epoch}\n",
    "        _stats.update({'train_loss':round(float(self.loss_train.compute()),self.precision),\n",
    "                  'valid_loss':round(float(self.loss_valid.compute()),self.precision)})\n",
    "        _stats.update({name:round(float(metric.compute()),self.precision) for name, metric in self.metrics.items()})\n",
    "        _stats.update({'elapsed':str(datetime.now() - self.st)})\n",
    "\n",
    "        self.stats_epoch.append(_stats)\n",
    "        self.loss_train.reset(); self.loss_valid.reset(); [metric.reset() for _,metric in self.metrics.items()];\n",
    "\n",
    "        self.log(_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeviceCB'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeviceCB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeviceCB:\n",
    "    def __init__(self, device=def_device): store_attr()\n",
    "    def before_fit(self, trainer):\n",
    "        if hasattr(trainer.model, 'to'): trainer.model.to(self.device)\n",
    "    def before_batch(self, trainer): \n",
    "        trainer.batch = to_device(trainer.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class Trainer:\n",
    "    def __init__(self, dls, loss_func, opt_func, model, callbacks):\n",
    "        self.callbacks = [o.__class__.__name__ for o in callbacks]\n",
    "        for callback in callbacks: setattr(self,callback.__class__.__name__,callback)\n",
    "        store_attr(but='callbacks')\n",
    "\n",
    "    def one_batch(self):\n",
    "        self.run_callbacks('before_batch')\n",
    "        self.preds = self.model(self.batch[self.dls.x_name])\n",
    "        self.loss = self.loss_func(self.preds, self.batch[self.dls.y_name])\n",
    "        if self.training:\n",
    "            self.run_callbacks('before_backward')\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        self.run_callbacks('after_batch')\n",
    "\n",
    "    def one_epoch(self):\n",
    "        self.run_callbacks('before_epoch')\n",
    "        \n",
    "        self.model.train()\n",
    "        self.run_callbacks('before_train')\n",
    "        for self.batch in self.dls.train: self.one_batch()\n",
    "        self.run_callbacks('after_train')\n",
    "\n",
    "        self.model.eval()\n",
    "        self.run_callbacks('before_valid')\n",
    "        for self.batch in self.dls.valid: self.one_batch()\n",
    "        self.run_callbacks('after_valid')\n",
    "        \n",
    "        self.run_callbacks('after_epoch')\n",
    "\n",
    "    def fit(self, epochs=3, lr=1e-3):\n",
    "        self.run_callbacks('before_fit')\n",
    "        self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "        for self.epoch in range(epochs): self.one_epoch()\n",
    "        self.run_callbacks('after_fit')\n",
    "\n",
    "    @property\n",
    "    def training(self): return self.model.training\n",
    "\n",
    "    def run_callbacks(self,method_name): \n",
    "        cbs = [getattr(self,o) for o in self.callbacks]\n",
    "        run_callbacks(cbs,method_name,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  SimpleNet(784,64,10), \n",
    "                  callbacks=[ProgressCB(Accuracy=MulticlassAccuracy()), DeviceCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'train_loss': 1.9606, 'valid_loss': 1.5961, 'Accuracy': 0.5721, 'elapsed': '0:00:00.713703'}\n",
      "{'epoch': 1, 'train_loss': 1.3458, 'valid_loss': 1.1409, 'Accuracy': 0.686, 'elapsed': '0:00:00.680809'}\n",
      "{'epoch': 2, 'train_loss': 1.0085, 'valid_loss': 0.9116, 'Accuracy': 0.714, 'elapsed': '0:00:00.693204'}\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
