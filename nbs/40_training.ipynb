{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n",
    "\n",
    "> Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from isaacai.utils import *\n",
    "from isaacai.dataloaders import *\n",
    "from isaacai.models import *\n",
    "\n",
    "from datetime import datetime\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd , numpy as np\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)\n",
    "_dataset = sample_dataset_dict(_dataset)\n",
    "dls = DataLoaders.from_dataset_dict(_dataset, 64, num_workers=4)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_callbacks(callbacks, method_name, trainer=None):\n",
    "    for callback in sorted(callbacks, key=lambda x: getattr(x, 'order',0)):\n",
    "        callback_method = getattr(callback, method_name,None)\n",
    "        if callback_method is not None: callback_method(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetricsCB:\n",
    "    def __init__(self, precision=4, **metrics):\n",
    "        self._precision=precision\n",
    "        self.metrics = metrics\n",
    "        self.metrics.update({'train_loss':Mean(),'valid_loss':Mean()})\n",
    "        \n",
    "    def _log(self,x): \n",
    "        _ff = fc.bind(round,ndigits=self._precision)\n",
    "        for name in self.metrics.keys(): x[name]=_ff(x[name])\n",
    "        x['elapsed'] = str(x['elapsed'])\n",
    "        print(x)\n",
    "    \n",
    "    def before_batch(self,trainer): self.batch_size = len(trainer.batch[1])\n",
    "    \n",
    "    def after_batch(self,trainer):\n",
    "        if trainer.training: \n",
    "            self.metrics['train_loss'].update(to_cpu(trainer.loss),weight=self.batch_size)\n",
    "        else: \n",
    "            self.metrics['valid_loss'].update(to_cpu(trainer.loss),weight=self.batch_size)\n",
    "            for name, metric in self.metrics.items():\n",
    "                if name in ('train_loss','valid_loss'): continue\n",
    "                self.metrics[name].update(to_cpu(trainer.preds),to_cpu(trainer.batch[1]))\n",
    "            \n",
    "    def before_epoch(self,trainer): self._st = datetime.now()\n",
    "    def after_epoch(self,trainer):\n",
    "        # compute metrics and append to epoch stats and display\n",
    "        log = {name:float(metric.compute()) for name, metric in self.metrics.items()}    \n",
    "        log['epoch'] = trainer.epoch\n",
    "        log['elapsed'] = datetime.now() - self._st\n",
    "        self._log(log)\n",
    "        [metric.reset() for metric in self.metrics.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeviceCB:\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, trainer):\n",
    "        if hasattr(trainer.model, 'to'): trainer.model.to(self.device)\n",
    "    def before_batch(self, trainer): \n",
    "        trainer.batch = to_device(trainer.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_callbacks(trainer,callbacks):\n",
    "    for callback in callbacks: \n",
    "        trainer.callbacks.append(callback.__class__.__name__)\n",
    "        setattr(trainer,callback.__class__.__name__,callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasicTrainCB:\n",
    "    def predict(self,trainer): trainer.preds = trainer.model(trainer.batch[0])\n",
    "    def get_loss(self,trainer): trainer.loss = trainer.loss_func(trainer.preds,trainer.batch[1])\n",
    "    def backward(self,trainer): trainer.loss.backward()\n",
    "    def step(self,trainer): trainer.opt.step()\n",
    "    def zero_grad(self,trainer): trainer.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class Trainer:\n",
    "    def subclassing_method(self,**kwargs): pass\n",
    "\n",
    "    @fc.delegates(to=subclassing_method)\n",
    "    def __init__(self, dls, loss_func, opt_func, model, callbacks,**kwargs):\n",
    "        self.callbacks = fc.L()\n",
    "        self.add_callbacks(getattr(self,'base_callbacks',fc.L()))\n",
    "        self.add_callbacks(callbacks)\n",
    "        fc.store_attr(but='callbacks')\n",
    "        self.subclassing_method(**kwargs)\n",
    "        self.run_callbacks('after_init')\n",
    "        \n",
    "            \n",
    "    def add_callbacks(self,callbacks): add_callbacks(self,callbacks)\n",
    "    \n",
    "    def one_batch(self):\n",
    "        self.run_callbacks('before_batch')\n",
    "        self.run_callbacks('predict')\n",
    "        self.run_callbacks('get_loss')\n",
    "        if self.training:\n",
    "            self.run_callbacks('before_backward')\n",
    "            self.run_callbacks('backward')\n",
    "            self.run_callbacks('step')\n",
    "            self.run_callbacks('zero_grad')\n",
    "        self.run_callbacks('after_batch')\n",
    "\n",
    "    def one_epoch(self):\n",
    "        self.run_callbacks('before_epoch')\n",
    "        self.model.train() # Training Loop\n",
    "        self.run_callbacks('before_train')\n",
    "        for self.batch in self.dls.train: self.one_batch()\n",
    "        self.run_callbacks('after_train')\n",
    "        self.model.eval()\n",
    "        self.run_callbacks('before_valid')\n",
    "        for self.batch in self.dls.valid: self.one_batch()\n",
    "        self.run_callbacks('after_valid')\n",
    "        self.run_callbacks('after_epoch')\n",
    "\n",
    "    def fit(self, epochs=3, lr=1e-3):\n",
    "        self.run_callbacks('before_fit')\n",
    "        self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "        for self.epoch in range(epochs): self.one_epoch()\n",
    "        self.run_callbacks('after_fit')\n",
    "\n",
    "    @property\n",
    "    def training(self): return self.model.training\n",
    "\n",
    "    def run_callbacks(self,method_name): \n",
    "        cbs = [getattr(self,o) for o in self.callbacks]\n",
    "        run_callbacks(cbs,method_name,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  SimpleNet(28*28,64,10), \n",
    "                  callbacks=[BasicTrainCB(),MetricsCB(accuracy=MulticlassAccuracy()), DeviceCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MomentumTrainCB:\n",
    "    def __init__(self,mom): fc.store_attr()\n",
    "    def predict(self,trainer): trainer.preds = trainer.model(trainer.batch[0])\n",
    "    def get_loss(self,trainer): trainer.loss = trainer.loss_func(trainer.preds,trainer.batch[1])\n",
    "    def backward(self,trainer): trainer.loss.backward()\n",
    "    def step(self,trainer): trainer.opt.step()\n",
    "    def zero_grad(self,trainer): \n",
    "        with torch.no_grad():\n",
    "            for p in trainer.model.parameters(): p.grad *= self.mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def InitDelegates(learner,method='subclassing_method'):\n",
    "    learner.__init__ = fc.delegates(getattr(learner,method))(learner.__init__)\n",
    "    return learner   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@InitDelegates\n",
    "class MomentumTrainer(Trainer): \n",
    "    def subclassing_method(self,precision=0.85): \n",
    "        self.add_callbacks([MomentumTrainCB(precision),DeviceCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MomentumTrainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.SGD, \n",
    "                  SimpleNet(28*28,64,10), \n",
    "                  callbacks=[MetricsCB(Accuracy=MulticlassAccuracy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.198, 'train_loss': 2.2719, 'valid_loss': 2.2044, 'epoch': 0, 'elapsed': '0:00:01.018725'}\n",
      "{'Accuracy': 0.294, 'train_loss': 2.1569, 'valid_loss': 2.0836, 'epoch': 1, 'elapsed': '0:00:00.355708'}\n",
      "{'Accuracy': 0.376, 'train_loss': 2.0255, 'valid_loss': 1.966, 'epoch': 2, 'elapsed': '0:00:00.349832'}\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
