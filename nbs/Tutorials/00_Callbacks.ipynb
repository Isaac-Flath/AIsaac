{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ffbf61-9481-4824-8522-7200a88f7db1",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc79a30-d809-4631-b0bb-aee0f7c7c0cd",
   "metadata": {},
   "source": [
    "The `isaacai` library is an extremely flexible framework that uses callbacks **a lot**.  They are probably more widely used than in any other framework.  It's super heavily influenced by callbacks system in the `miniai` library developed as part of the fastai course, but goes a bit further in that direction in a couple of aspects.  Because of this it's very important to understand how to use `isaacai` uses them and how you can leverage that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8b0af-d88f-4258-9ae2-a12482056cbc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here I will set up the needed pieces for the tutorial.  This includes imports and loading a small subset of the fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cda67-fa0d-4a01-a9d0-c43a4e1263bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75d55b-d644-4383-ab1e-872607c47394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isaacai.all import *\n",
    "import fastcore.all as fc\n",
    "import matplotlib.pyplot as plt,matplotlib as mpl\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a860278-7a7d-477e-b755-ae7aad038b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b470376-1fb5-40da-aeff-94aa4dda9853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03089141845703125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d032f335c3bc4641b96499e588e21d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmean,xstd = 0.28, 0.35\n",
    "@inplace\n",
    "def transformi(b): b['image'] = [(TF.to_tensor(o)-xmean)/xstd for o in b['image']]\n",
    "\n",
    "_dataset = load_dataset('fashion_mnist').with_transform(transformi)\n",
    "_dataset = sample_dataset_dict(_dataset)\n",
    "dls = DataLoaders.from_dataset_dict(_dataset, 64, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400045d-2fb0-44b8-8794-110686c820df",
   "metadata": {},
   "source": [
    "## Basic Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730075e5-a3d0-46bb-8e2e-dbc96d47f449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.295757</td>\n",
       "      <td>2.273843</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train     valid  Accuracy\n",
       "0  2.295757  2.273843     0.152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ea4c thead {\n",
       "  display: none;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ea4c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ea4c_level0_col0\" class=\"col_heading level0 col0\" >train</th>\n",
       "      <th id=\"T_3ea4c_level0_col1\" class=\"col_heading level0 col1\" >valid</th>\n",
       "      <th id=\"T_3ea4c_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ea4c_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_3ea4c_row0_col0\" class=\"data row0 col0\" >2.234482</td>\n",
       "      <td id=\"T_3ea4c_row0_col1\" class=\"data row0 col1\" >2.159061</td>\n",
       "      <td id=\"T_3ea4c_row0_col2\" class=\"data row0 col2\" >0.292000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_51e9e thead {\n",
       "  display: none;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_51e9e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_51e9e_level0_col0\" class=\"col_heading level0 col0\" >train</th>\n",
       "      <th id=\"T_51e9e_level0_col1\" class=\"col_heading level0 col1\" >valid</th>\n",
       "      <th id=\"T_51e9e_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_51e9e_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_51e9e_row0_col0\" class=\"data row0 col0\" >2.041413</td>\n",
       "      <td id=\"T_51e9e_row0_col1\" class=\"data row0 col1\" >1.833673</td>\n",
       "      <td id=\"T_51e9e_row0_col2\" class=\"data row0 col2\" >0.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(dls,\n",
    "                  nn.CrossEntropyLoss(), \n",
    "                  torch.optim.Adam, \n",
    "                  model = get_model_conv(),\n",
    "                  callbacks=[BasicTrainCB(),MetricsCB(Accuracy=MulticlassAccuracy()), DeviceCB(),ProgressCB()])\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf2d5d-2531-4955-af61-d61b355bf4a0",
   "metadata": {},
   "source": [
    "So we passed in a `DataLoaders`, a pytorch loss, a pytorch optimizer, a pytorch model, and some callbacks.  As you can see by running `Trainer.fit` it ran a full training loop.  **The training loop is defined entirely in the callbacks**.  For this tutorial we are focusing on the callbacks.  Please refer to pytorch documentation for the pytorch pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45e8ee-ab8f-456c-8da5-28b74ceefa35",
   "metadata": {},
   "source": [
    "### One batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9a62c-8bcb-4938-9a91-2164c9bc5f48",
   "metadata": {},
   "source": [
    "Let's see how a batch is processed.  The source code for the batch trainer is very small and there's two things we need to understand about it, the decorator and the run_callbacks method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832b365-6cbb-4c80-8b96-3bb260a533e0",
   "metadata": {},
   "source": [
    "```python\n",
    "@with_cbs('batch', CancelBatchException)\n",
    "def one_batch(self):\n",
    "    self.run_callbacks(['predict','get_loss'])\n",
    "    if self.training: self.run_callbacks(['before_backward','backward','step','zero_grad'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740fcda-2fd2-4f0b-854a-45ab1e9c7ef9",
   "metadata": {},
   "source": [
    "#### `run_callbacks`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296ffd3-ff3a-4a45-890c-3d0a294d7e46",
   "metadata": {},
   "source": [
    "The `run_callbacks` method is what actually executes the callbacks code.  As you can see a batch is just all callbacks. \n",
    "\n",
    "The first `run_callbacks` does the following:\n",
    "\n",
    "::: {.callout-tip}\n",
    "\n",
    "##### run_callbacks pseudo code\n",
    "+ Sorts all callbacks according to the \"order\" attribute (defaults to 0)\n",
    "+ Loops through `['predict','get_loss']`\n",
    "    + Loops through ordered callbacks:\n",
    "        + If \"predict\" method exists for that callback then run it\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2a141-80ba-45f9-9fb4-96ed1f754609",
   "metadata": {},
   "source": [
    "Let's look at the `BasicTrainCB` code.  As you can see, each element needed to process the batch is here.  \"before_backward\" is not defined so this callback won't do anything in that step.  We could however define a callback that happens before the backward pass if we want to add functionality to our trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee048c94-e59d-4037-88fa-fcaa1a7bbb48",
   "metadata": {},
   "source": [
    "```python\n",
    "class BasicTrainCB:\n",
    "    def predict(self,trainer): trainer.preds = trainer.model(trainer.batch[0])\n",
    "    def get_loss(self,trainer): trainer.loss = trainer.loss_func(trainer.preds,trainer.batch[1])\n",
    "    def backward(self,trainer): trainer.loss.backward()\n",
    "    def step(self,trainer): trainer.opt.step()\n",
    "    def zero_grad(self,trainer): trainer.opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae90fc-f825-4738-a1a0-0b7d62bf0207",
   "metadata": {},
   "source": [
    "#### `with_cbs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3490c45-fd8d-44f0-bb99-7d6c11a8157c",
   "metadata": {},
   "source": [
    "With cbs adds two pieces of functionality.\n",
    "\n",
    "+ Ability to exit and skip the rest of the function (ie the batch).  This is similar to how you can use `continue` in a for loop.  This can be done with raising the particular `exception`.\n",
    "+ Adds before, after, and cleanup callbacks to the function.  Before and after run before and after the function.  Cleanup will always run, even if an exception is thrown.\n",
    "\n",
    "::: {.callout-tip}\n",
    "##### `one_batch` example\n",
    "\n",
    "+ To run a callback before or after every batch, you would use `before_batch` and `after_batch`\n",
    "+ To skip a batch, you would raise a `CancelBatchException` in a callback as that's what is passed to the decorator.\n",
    "+ The `cleanup_batch` callback will always run if one exists, even if you skipped the batch.  `after_batch` will be skipped once the `CancelBatchException` is raised.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a37e93-a55e-434e-87c1-fedaea39b862",
   "metadata": {},
   "source": [
    "```python\n",
    "class with_cbs:\n",
    "    def __init__(self, nm, exception): fc.store_attr()\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.run_callbacks(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.run_callbacks(f'after_{self.nm}')\n",
    "            except self.exception: pass\n",
    "            finally: o.run_callbacks(f'cleanup_{self.nm}')\n",
    "        return _f\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022dcfa-d131-40a8-9f23-968c441a2962",
   "metadata": {},
   "source": [
    "### Other Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca10213-7911-406b-acb5-cd91821ee516",
   "metadata": {},
   "source": [
    "Another example of a callback is the device callback, that puts things onto whatever device we want (ie GPU)\n",
    "\n",
    "```python\n",
    "class DeviceCB:\n",
    "    def __init__(self, device=def_device): self.def_device=def_device\n",
    "    def before_fit(self, trainer):\n",
    "        if hasattr(trainer.model, 'to'): trainer.model.to(self.device)\n",
    "    def before_batch(self, trainer): trainer.batch = to_device(trainer.batch, device=self.device)\n",
    "```    \n",
    "\n",
    "In addition, the `MetricsCB` in the example above is responsible for calculating and tracking the losses, the metrics it's initalized with, and logging that every epoch.\n",
    "\n",
    "**All functionality that is done in the training loop is managed through callbacks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4783f-5d9e-4d01-8d07-20431dc84286",
   "metadata": {},
   "source": [
    "Epochs work similarly to batches with callbacks, and there is also a fit method which also executes callbacks in the same way.  \n",
    "\n",
    "::: {.callout-tip}\n",
    "##### Available Callback List\n",
    "\n",
    "+ Batch callbacks\n",
    "    + before_batch\n",
    "    + predict\n",
    "    + get_loss\n",
    "    + before_backward\n",
    "    + backward\n",
    "    + step\n",
    "    + zero_grad\n",
    "    + after_batch\n",
    "    + cleanup_batch\n",
    "+ Epoch callbacks\n",
    "    + before_epoch\n",
    "    + after_epoch\n",
    "    + cleanup_epoch\n",
    "+ Fit callbacks\n",
    "    + before_fit\n",
    "    + after_fit\n",
    "    + cleanup_fit\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fc190-5396-4d6f-9982-4796f6226f3f",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "##### Cancel Exceptions\n",
    "\n",
    "+ CancelBatchException\n",
    "+ CancelEpochException\n",
    "+ CancelFitException\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84518a-d27b-40b0-83b6-bdacabd843bd",
   "metadata": {},
   "source": [
    "## Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d2496-5732-4791-9347-d0d36e5f9892",
   "metadata": {},
   "source": [
    "Now that we know how to modify and extend the training loop, the next thing we want to do is subclass.  It would be really annoying if we had to remember too pass in the right combination of callbacks every time!  As an example, let's create a MomentumTrainer that has momentum using a GPU if it's available.  There's 2 steps for that.  \n",
    "\n",
    "1. Create a `MomentumTrainCB` similar to the `BasicTrainCB` above but implements momentum\n",
    "1. Create a `MomentumTrainer` similar to `Trainer` above that uses the appropriate callbacks without us having to add them in\n",
    "1. Update `__init__` function signature so we get information on any new parameters for those callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a075ef-be76-4964-bb5d-e4c1213fdc92",
   "metadata": {},
   "source": [
    "### MomentumTrainCB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efbe9d-c9e5-43cd-a3d4-3aff770a5b0a",
   "metadata": {},
   "source": [
    "We can inherit from the `BasicTrainCB` about because momentum is mostly the same as a normal training loop with one small tweak that allows previous gradients to be accounted for.\n",
    "\n",
    "```python\n",
    "class MomentumTrainCB(BasicTrainCB):\n",
    "    def __init__(self,momentum): self.momentum = momentum\n",
    "    def zero_grad(self,trainer): \n",
    "        with torch.no_grad():\n",
    "            for p in trainer.model.parameters(): p.grad *= self.mom\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa3cb4-6699-4540-9d13-8881bcb25c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
