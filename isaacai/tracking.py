# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/60_tracking.ipynb.

# %% auto 0
__all__ = ['sql_connect', 'TrackingCB']

# %% ../nbs/60_tracking.ipynb 4
from .utils import *
from .dataloaders import *
from .models import *
from .training import *
import inspect

from datetime import datetime
import torchvision.transforms.functional as TF,torch.nn.functional as F

import matplotlib.pyplot as plt,matplotlib as mpl
import fastcore.all as fc
import torch
from torch import nn, Tensor
from datasets import load_dataset, Dataset
from torch.utils.data import DataLoader
import pandas as pd , numpy as np
from torcheval.metrics import MulticlassAccuracy,Mean

import sqlite3
from pathlib import Path
import pandas as pd

# %% ../nbs/60_tracking.ipynb 7
def sql_connect(path): return sqlite3.connect(path)

# %% ../nbs/60_tracking.ipynb 8
class TrackingCB:
    def __init__(self, db_path,exp_name):
        self._exp_name = exp_name
        self._con = sql_connect(db_path)
        self._log_epoch,self._log_batch, self._log_fit = [pd.DataFrame()]*3
        
    def before_fit(self,trainer):
        if getattr(trainer,'MetricsCB',None) is not None: setattr(getattr(trainer,'MetricsCB'),'_log',self._log)
        log = {'model':str(trainer.model),'model_type':str(type(trainer.model)),'model_source':inspect.getsource(trainer.model.__class__)}
        log['callbacks'] = str(trainer.callbacks)

        for callback in trainer.callbacks:
            cb = getattr(trainer,callback)
            cb_attrs = dir(cb)
            for cb_attr in cb_attrs:
                if cb_attr.startswith('_'): continue
                if not callable(getattr(cb,cb_attr)): log[cb_attr] = str(getattr(cb,cb_attr))
        self._log(log)
        
    def _log(self,x):
        x['insert_timestamp'] = datetime.now()
        x['exp_name'] = self._exp_name
        log = pd.DataFrame(x,index=[""])
        if 'batch' in x.keys(): self._log_batch = pd.concat([self._log_batch,log])
        elif 'epoch' in x.keys(): self._log_epoch = pd.concat([self._log_epoch,log])
        else: self._log_fit = pd.concat([self._log_fit,log])
        
    
    def after_fit(self, trainer):
        self._log_batch.to_sql('batch_stats', self._con, if_exists='append')
        self._log_epoch.to_sql('epoch_stats', self._con, if_exists='append')
        self._log_fit.to_sql('fit_stats', self._con, if_exists='append')

